{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper libraries\n",
    "import numpy as np\n",
    "import random\n",
    "%matplotlib inline\n",
    "# import matplotlib\n",
    "# matplotlib.use('TkAgg')# Backend needed for the Mac virtual env\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_random_number(seed):\n",
    "    # see https://stackoverflow.com/a/52897216\n",
    "    np.random.seed(seed)\n",
    "    tf.set_random_seed(seed)\n",
    "    os.environ['PYTHONHASHSEED']=str(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "random_seed = 1\n",
    "seed_random_number(random_seed)\n",
    "#####################\n",
    "# from keras import backend as K\n",
    "# # see https://stackoverflow.com/a/52897216 we really need singlethread to get\n",
    "# # reproducible results!\n",
    "# session_conf = tensorflow.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "# sess = tensorflow.Session(graph=tensorflow.get_default_graph(), config=session_conf)\n",
    "# K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required for live plotting of errors while training\n",
    "# Taken and adapted from:\n",
    "# https://github.com/kapil-varshney/utilities/blob/master/training_plot/training_plot_ex_with_cifar10.ipynb\n",
    "class TrainingPlot(keras.callbacks.Callback):\n",
    "    \n",
    "    # This function is called when the training begins\n",
    "    def on_train_begin(self, logs={}):\n",
    "        # Initialize the lists for holding the logs, losses\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        self.logs = []\n",
    "    \n",
    "    # This function is called at the end of each epoch\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        # Append the logs, losses to the lists\n",
    "        self.logs.append(logs)\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "        \n",
    "        # Before plotting ensure at least 2 epochs have passed\n",
    "        if epoch > 1 and epoch%500 == 0:\n",
    "            \n",
    "            # Clear the previous plot\n",
    "            clear_output(wait=True)\n",
    "            N = np.arange(0, len(self.losses))\n",
    "            \n",
    "            # Plot train loss, train acc, val loss and val acc against epochs passed\n",
    "            plt.figure()\n",
    "            plt.loglog(N, self.losses, label = \"train_loss\")\n",
    "            plt.loglog(N, self.val_losses, label = \"val_loss\")\n",
    "            plt.title(\"Training Loss [Epoch {}]\".format(epoch))\n",
    "            plt.xlabel(\"Epoch #\")\n",
    "            plt.ylabel(\"Loss\")\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "\n",
    "plot_losses = TrainingPlot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data set:\n",
    "# Dividing data into train, validation, test sets\n",
    "Nsamples = 2000\n",
    "Ntrain   = 128\n",
    "Nvalid   = 128\n",
    "\n",
    "x = np.random.rand(Nsamples,1)\n",
    "y = 2.0 + np.sin(8*np.pi*x)\n",
    "\n",
    "train_input = x[0:Ntrain,:]\n",
    "train_truth = y[0:Ntrain,:]\n",
    "valid_input = x[Ntrain:Ntrain+Nvalid,:]\n",
    "valid_truth = y[Ntrain:Ntrain+Nvalid,:]\n",
    "test_input = x[Ntrain+Nvalid:-1,:]\n",
    "test_truth = y[Ntrain+Nvalid:-1,:]\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.subplot(3,1,1)\n",
    "plt.plot(train_input,train_truth,'o',Color='red')\n",
    "plt.draw()\n",
    "\n",
    "plt.subplot(3,1,2)\n",
    "plt.plot(valid_input,valid_truth,'o',Color='red')\n",
    "plt.draw()\n",
    "\n",
    "plt.subplot(3,1,3)\n",
    "plt.plot(test_input,test_truth,'o',Color='red')\n",
    "plt.draw()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function describing network architecture\n",
    "# DEMONOSTRATE ISSUE OF DYING NEURONS\n",
    "# RELU Doesnt work. But Leaky ReLU does\n",
    "def create_model():\n",
    "\n",
    "  model = keras.Sequential([\n",
    "          keras.layers.Dense(20, input_shape = (1,), activation=tf.keras.layers.ReLU(max_value=None), use_bias=True, kernel_initializer='RandomNormal', bias_initializer='RandomNormal'),\n",
    "          keras.layers.Dense(20, activation=tf.keras.layers.ReLU(max_value=None), use_bias=True, kernel_initializer='RandomNormal', bias_initializer='RandomNormal'),\n",
    "          keras.layers.Dense(20, activation=tf.keras.layers.ReLU(max_value=None), use_bias=True, kernel_initializer='RandomNormal', bias_initializer='RandomNormal'),\n",
    "          keras.layers.Dense(20, activation=tf.keras.layers.ReLU(max_value=None), use_bias=True, kernel_initializer='RandomNormal', bias_initializer='RandomNormal'),\n",
    "          keras.layers.Dense(20, activation=tf.keras.layers.ReLU(max_value=None), use_bias=True, kernel_initializer='RandomNormal', bias_initializer='RandomNormal'),\n",
    "          keras.layers.Dense(1, use_bias=True, kernel_initializer='RandomNormal', bias_initializer='RandomNormal')\n",
    "  ])\n",
    "\n",
    "#   model = keras.Sequential([\n",
    "#           keras.layers.Dense(20, input_shape = (1,), activation=tf.keras.layers.LeakyReLU(alpha=0.01), use_bias=True, kernel_initializer='RandomNormal', bias_initializer='RandomNormal'),\n",
    "#           keras.layers.Dense(20, activation=tf.keras.layers.LeakyReLU(alpha=0.01), use_bias=True, kernel_initializer='RandomNormal', bias_initializer='RandomNormal'),\n",
    "#           keras.layers.Dense(20, activation=tf.keras.layers.LeakyReLU(alpha=0.01), use_bias=True, kernel_initializer='RandomNormal', bias_initializer='RandomNormal'),\n",
    "#           keras.layers.Dense(20, activation=tf.keras.layers.LeakyReLU(alpha=0.01), use_bias=True, kernel_initializer='RandomNormal', bias_initializer='RandomNormal'),\n",
    "#           keras.layers.Dense(20, activation=tf.keras.layers.LeakyReLU(alpha=0.01), use_bias=True, kernel_initializer='RandomNormal', bias_initializer='RandomNormal'),\n",
    "#           keras.layers.Dense(1, use_bias=True, kernel_initializer='RandomNormal', bias_initializer='RandomNormal')\n",
    "#   ])\n",
    "\n",
    "  \n",
    "  model.compile(optimizer=keras.optimizers.Adam(), \n",
    "                loss='mse',\n",
    "                metrics=['mse'])\n",
    "  \n",
    "  return model\n",
    "\n",
    "model = create_model()\n",
    "model.summary()\n",
    "#model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "model.fit(train_input, \n",
    "          train_truth, \n",
    "          epochs=15000, \n",
    "          verbose=0, \n",
    "          batch_size=32, \n",
    "          shuffle=True, \n",
    "          validation_data=(valid_input,valid_truth),\n",
    "          callbacks=[plot_losses]\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Performance of trained model\n",
    "train_loss, train_mse = model.evaluate(train_input, train_truth)\n",
    "print('Test accuracy:', train_mse)\n",
    "\n",
    "valid_loss, valid_mse = model.evaluate(valid_input, valid_truth)\n",
    "print('Test accuracy:', valid_mse)\n",
    "\n",
    "test_loss, test_mse = model.evaluate(test_input, test_truth)\n",
    "print('Test accuracy:', test_mse)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.subplot(3,1,1)\n",
    "plt.plot(train_input,train_truth,'o',Color='red')\n",
    "plt.plot(train_input,model.predict(train_input),'x',Color='blue')\n",
    "plt.draw()\n",
    "\n",
    "plt.subplot(3,1,2)\n",
    "plt.plot(valid_input,valid_truth,'o',Color='red')\n",
    "plt.plot(valid_input,model.predict(valid_input),'x',Color='blue')\n",
    "plt.draw()\n",
    "\n",
    "plt.subplot(3,1,3)\n",
    "plt.plot(test_input,test_truth,'o',Color='red')\n",
    "plt.plot(test_input,model.predict(test_input),'x',Color='blue')\n",
    "plt.draw()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_venv",
   "language": "python",
   "name": "dl_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
